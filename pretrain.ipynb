{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "1f686d4f-84c1-4000-8b21-a75a444e0896"
   },
   "source": [
    "# Build synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "69f33af7-a759-4838-9ba9-8da07cc70eeb"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"./webtext2019zh/web_text_zh_train_sample.json\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "content = map(json.loads, content)\n",
    "content = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "1766db94-5e8a-41c1-9814-c9f0999d69d1"
   },
   "outputs": [],
   "source": [
    "text = \"\\n\".join(content.content.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "cb319deb-d6ce-45aa-b557-08585f25a654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 558 µs, sys: 0 ns, total: 558 µs\n",
      "Wall time: 564 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "\n",
    "def cut_sentences(text, min_len=3):\n",
    "    \"\"\"\n",
    "    Cut sentences by their length and punctuation\n",
    "    \"\"\"\n",
    "    corpus = re.split(\"[\\,\\.\\?，。？\\n]\", text)\n",
    "    corpus = list(filter(lambda x: len(x) >= min_len, corpus))\n",
    "    return corpus\n",
    "\n",
    "sentences = cut_sentences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "uuid": "fb0d53a4-fdfc-4f63-9aeb-2285e7a5d588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我对你仍有爱意',\n",
       " '我对自己无能为力',\n",
       " '讲一个同学的事儿吧 那年他小学二年级 数学课 老师讲课的时候 同学跟同桌一块儿玩儿 小孩儿贪玩也很寻常 不寻常的是数学老师勃然大怒 抓起我同学的衣领 拎着他就直接走出教室 教室是在四楼 这老师竟然直接就把他悬在了走道护杆外的半空 同学直接吓尿了（是真的尿）这老师还在骂骂咧咧的威胁以后还敢不敢上课瞎捣蛋 结局同学还是安然被“收了回来” 但从此他不敢在数学课上放肆 从此他的数学成绩没有突破过及格线 一个好的老师 传',\n",
       " '我看了上帝之眼感觉还不错',\n",
       " '不喜欢那些讲技术的摄影书',\n",
       " ' 喜欢美用诗意和哲理来表现',\n",
       " '汉子已经被我收啦 现在是男票了哈哈哈哈哈 放两张聊天记录你们感受下',\n",
       " '看到这一幕我简直兴奋得要上天了 更新于上一个答案几个小时后 剧透醒目 论这个世界上还有什么比妖怪夫妇联手更恐怖的事',\n",
       " '小时候喜欢芭比娃娃',\n",
       " '太贵买不起']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "68264c8c-5fb7-49d7-bd7d-1e4d2b9ab0ec"
   },
   "source": [
    "# Mask filling\n",
    "Inserting masks at random positions in the Wikipedia sentences, and fill them with the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "uuid": "b1d52f55-d10c-4677-b95f-9ad170b0efb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(range(10), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "uuid": "179bc5b6-a76f-4eea-8b31-129851290858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.19 ms, sys: 0 ns, total: 5.19 ms\n",
      "Wall time: 5.15 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                    我对你仍有<MASK><MASK>\n",
       "1                              我对自<MASK><MASK><MASK>为力\n",
       "2    讲一个同学的事儿吧 那年他小学二年级 数学课 老师讲课的时候 同学跟同桌一块儿玩儿 小孩儿贪...\n",
       "3                          我看了上帝之眼<MASK><MASK><MASK>不错\n",
       "4                               不喜欢那些讲技<MASK><MASK>摄影书\n",
       "dtype: object"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import math\n",
    "\n",
    "s = \"看到这一幕我简直兴奋得要上天了 更新于上一个答案几个小时后 剧透醒目 论这个世界上还有什么比妖怪夫妇联手更恐怖的事\"\n",
    "\n",
    "def mask_filling(s):\n",
    "    \"\"\"\n",
    "    The first strategy samples random wordsin the sentence and it replaces them with masks(one for each token).\n",
    "    \"\"\"\n",
    "    seq = list(s)\n",
    "    seq_len = len(s)\n",
    "    # Sample from 1 to half chars of the sequence\n",
    "    k = random.randint(1, math.floor(seq_len * 0.75))\n",
    "    token_idx = random.choices(range(seq_len), k = k)\n",
    "    for i in token_idx:\n",
    "        seq[i] = \"<MASK>\"\n",
    "    return \"\".join(seq)\n",
    "\n",
    "def mask_filling2(s):\n",
    "    \"\"\"\n",
    "    The second strategy cre-ates contiguous sequences: \n",
    "    it samples a start po-sition s, a length l (uniformly distributed), \n",
    "    and it masks all the tokens spanned by words betweenpositions s and s + l.\n",
    "    \"\"\"\n",
    "    seq_len = len(s)\n",
    "    start = random.randint(1, seq_len-1)\n",
    "    # At least mask 15% words, greater than 1\n",
    "    min_length = min(math.floor(seq_len * 0.15), seq_len - start)\n",
    "    min_length = max(min_length, 1)\n",
    "    # At most 85% of words\n",
    "    max_length = min(math.floor(seq_len * 0.85), seq_len - start)\n",
    "    max_length = max(min_length, max_length)\n",
    "    length = random.choice(range(min_length, max_length+1))\n",
    "    \n",
    "    s = s[:start] + \"<MASK>\" * length + s[(start+length):]\n",
    "    return s\n",
    "\n",
    "pd.Series(sentences).apply(mask_filling2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "uuid": "5e7af25b-fd2c-499f-b33e-da01b92e1cae"
   },
   "outputs": [],
   "source": [
    "# Use GPT2 to fill in the missing fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "7243e167-3fc5-4220-b1ad-e527e24c84fd"
   },
   "source": [
    "# Backtranslation\n",
    "Translate chinese to english, and translate back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "b6a5c9ca-613e-4ea3-909c-a45c97a3a2a6"
   },
   "source": [
    "# Word dropping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
