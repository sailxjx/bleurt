# 生成预训练数据集

`data_generation.py` 一键生成数据集

# TODO

* [x] 目前样本中没有反义句对,例如"是 xx"和"不是 xx",这造成最终训练完成的模型可能给两个反义句的评分是较高的,而期望的结果是这样的句对评分应该是极低的.需要从样本中挑出反义句对,手动标记为0
* [ ] 样本中 mask filling 用的 bert 模型没有在样本中做 finetune,这导致了很多填充的结果无法变成一句通顺的句子,而这类句子目前的评分过高.需要 finetune 模型,并且调整这种生成方式下的句对评分.

