{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "ac560a96-32a9-4781-b6e7-0ebea5590fe8"
   },
   "source": [
    "# Build synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "uuid": "3cb8e3aa-eab6-4f5a-bc0e-51a76e6b889e"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"./webtext2019zh/web_text_zh_train_sample.json\", \"r\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "content = map(json.loads, content)\n",
    "content = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "uuid": "19b59c7b-21b3-4a9d-864e-e832864d4566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 ms, sys: 1e+03 ns, total: 2.04 ms\n",
      "Wall time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "\n",
    "def cut_sentences(text, min_len=3):\n",
    "    \"\"\"\n",
    "    Cut sentences by their length and punctuation, remove all spaces.\n",
    "    \"\"\"\n",
    "    text = text.replace(\" \", \"\")\n",
    "    corpus = re.split(\"[\\,\\.\\?，。？\\n]\", text)\n",
    "    corpus = list(filter(lambda x: len(x) >= min_len, corpus))\n",
    "    return corpus\n",
    "\n",
    "text = \"\\n\".join(content.content.values)\n",
    "sentences = cut_sentences(text)\n",
    "df = pd.DataFrame({\n",
    "    \"seq\": sentences\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "97f1f219-211b-4b2f-9a4b-4da319429176"
   },
   "source": [
    "# Mask filling\n",
    "Inserting masks at random positions in the Wikipedia sentences, and fill them with the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "uuid": "9bce873e-7b13-46fa-9a1c-272c6c49b61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 429 ms, sys: 5.01 ms, total: 434 ms\n",
      "Wall time: 432 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>masked</th>\n",
       "      <th>masked_rate</th>\n",
       "      <th>filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我对你仍有爱意</td>\n",
       "      <td>我对你仍有爱[MASK]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>我对你仍有感心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我对自己无能为力</td>\n",
       "      <td>我[MASK][MASK][MASK][MASK]能为力</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>我对自己无力力力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "      <td>0.198953</td>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我看了上帝之眼感觉还不错</td>\n",
       "      <td>我看了[MASK][MASK]之眼感觉还不错</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>我看了上帝之眼感觉的感。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不喜欢那些讲技术的摄影书</td>\n",
       "      <td>不喜欢那些讲技术的摄[MASK][MASK]</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>不、、、、、、、、、、、</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  \\\n",
       "0                                            我对你仍有爱意   \n",
       "1                                           我对自己无能为力   \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...   \n",
       "3                                       我看了上帝之眼感觉还不错   \n",
       "4                                       不喜欢那些讲技术的摄影书   \n",
       "\n",
       "                                              masked  masked_rate  \\\n",
       "0                                       我对你仍有爱[MASK]     0.142857   \n",
       "1                       我[MASK][MASK][MASK][MASK]能为力     0.500000   \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...     0.198953   \n",
       "3                             我看了[MASK][MASK]之眼感觉还不错     0.166667   \n",
       "4                             不喜欢那些讲技术的摄[MASK][MASK]     0.166667   \n",
       "\n",
       "                                              filled  \n",
       "0                                            我对你仍有感心  \n",
       "1                                           我对自己无力力力  \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...  \n",
       "3                                       我看了上帝之眼感觉的感。  \n",
       "4                                       不、、、、、、、、、、、  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import math\n",
    "\n",
    "s = \"看到这一幕我简直兴奋得要上天了 更新于上一个答案几个小时后 剧透醒目 论这个世界上还有什么比妖怪夫妇联手更恐怖的事\"\n",
    "\n",
    "def mask_replacing(s):\n",
    "    \"\"\"\n",
    "    The first strategy samples random words in the sentence and it replaces them with masks(one for each token).\n",
    "    \"\"\"\n",
    "    seq = list(s)\n",
    "    seq_len = len(s)\n",
    "    # Sample from 1 to 50% chars of the sequence\n",
    "    k = random.randint(1, math.floor(seq_len * 0.5))\n",
    "    token_idx = random.choices(range(seq_len), k = k)\n",
    "    for i in token_idx:\n",
    "        seq[i] = \"[MASK]\"\n",
    "    return \"\".join(seq)\n",
    "\n",
    "def mask_replacing2(s):\n",
    "    \"\"\"\n",
    "    The second strategy cre-ates contiguous sequences: \n",
    "    it samples a start po-sition s, a length l (uniformly distributed), \n",
    "    and it masks all the tokens spanned by words betweenpositions s and s + l.\n",
    "    \"\"\"\n",
    "    seq_len = len(s)\n",
    "    start = random.randint(1, seq_len-1)\n",
    "    # At least 10% of words\n",
    "    min_length = min(math.floor(seq_len * 0.1), seq_len - start)\n",
    "    min_length = max(min_length, 1)\n",
    "    # At most 50% of words\n",
    "    max_length = min(math.floor(seq_len * 0.5), seq_len - start)\n",
    "    max_length = max(min_length, max_length)\n",
    "    length = random.choice(range(min_length, max_length+1))\n",
    "    \n",
    "    s = s[:start] + \"[MASK]\" * length + s[(start+length):]\n",
    "    return pd.Series([s, length / seq_len], index=[\"masked\", \"masked_rate\"])\n",
    "\n",
    "masked_seqs = pd.Series(sentences).apply(mask_replacing2)\n",
    "df[\"masked\"] = masked_seqs[\"masked\"]\n",
    "df[\"masked_rate\"] = masked_seqs[\"masked_rate\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "80237f60-e7c7-4c91-a8d0-f53c6328faec"
   },
   "outputs": [],
   "source": [
    "# Fill in the masked fields\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/admin/workspace/model/transformers/bert-base-multilingual-cased')\n",
    "model = AutoModelForMaskedLM.from_pretrained('/home/admin/workspace/model/transformers/bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "ae0abd2e-5f21-4cd7-ad42-2acd74e14874"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "\n",
    "def mask_replacing(text):\n",
    "#     text = \"我对自[MASK][MASK]能为力\"\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    [predictions] = model(**encoded_input)\n",
    "\n",
    "    predicted_index = torch.argmax(predictions[0], dim=1).tolist()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens(predicted_index)\n",
    "    return \"\".join(predicted_token[1:-1])\n",
    "\n",
    "filled_seqs = df.masked.apply(mask_replacing).rename(\"filled\")\n",
    "df[\"filled\"] = filled_seqs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "uuid": "2198f764-0536-4c3c-9c10-19c9ed812d5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the weights of TFBertForMaskedLM were initialized from the model checkpoint at /home/admin/workspace/model/transformers/bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".我对自己功能为力力\n"
     ]
    }
   ],
   "source": [
    "# tensorflow model\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/admin/workspace/model/transformers/bert-base-multilingual-cased\")\n",
    "model = TFAutoModelWithLMHead.from_pretrained(\"/home/admin/workspace/model/transformers/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "uuid": "becc60ac-9c05-4137-9c23-1a4e454dc484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我对自己功能为力\n"
     ]
    }
   ],
   "source": [
    "text = \"我对自[MASK][MASK]能为力\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "[predictions] = model(encoded_input)\n",
    "\n",
    "predicted_index = tf.argmax(predictions[0], axis=1)\n",
    "predicted_token = tokenizer.convert_ids_to_tokens(predicted_index)\n",
    "print(\"\".join(predicted_token[1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "553b2b19-42b4-4e66-a69f-af6601c636a9"
   },
   "source": [
    "# Backtranslation\n",
    "Translate chinese to english, and translate back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "uuid": "23c6ab37-783d-4361-98c8-95ae782a86ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>masked</th>\n",
       "      <th>masked_rate</th>\n",
       "      <th>filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我对你仍有爱意</td>\n",
       "      <td>我对你仍有爱[MASK]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>我对你仍有爱。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我对自己无能为力</td>\n",
       "      <td>我[MASK][MASK][MASK][MASK]能为力</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>我的为心功能为力</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "      <td>0.198953</td>\n",
       "      <td>讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>我看了上帝之眼感觉还不错</td>\n",
       "      <td>我看了[MASK][MASK]之眼感觉还不错</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>我看了光光之眼感觉还不错</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不喜欢那些讲技术的摄影书</td>\n",
       "      <td>不喜欢那些讲技术的摄[MASK][MASK]</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>不喜欢那些讲技术的摄影师</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 seq  \\\n",
       "0                                            我对你仍有爱意   \n",
       "1                                           我对自己无能为力   \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...   \n",
       "3                                       我看了上帝之眼感觉还不错   \n",
       "4                                       不喜欢那些讲技术的摄影书   \n",
       "\n",
       "                                              masked  masked_rate  \\\n",
       "0                                       我对你仍有爱[MASK]     0.142857   \n",
       "1                       我[MASK][MASK][MASK][MASK]能为力     0.500000   \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...     0.198953   \n",
       "3                             我看了[MASK][MASK]之眼感觉还不错     0.166667   \n",
       "4                             不喜欢那些讲技术的摄[MASK][MASK]     0.166667   \n",
       "\n",
       "                                              filled  \n",
       "0                                            我对你仍有爱。  \n",
       "1                                           我的为心功能为力  \n",
       "2  讲一个同学的事儿吧那年他小学二年级数学课老师讲课的时候同学跟同桌一块儿玩儿小孩儿贪玩也很寻常...  \n",
       "3                                       我看了光光之眼感觉还不错  \n",
       "4                                       不喜欢那些讲技术的摄影师  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "uuid": "62afde4c-8896-4f3b-9e4b-ff82b25ff03a"
   },
   "source": [
    "# Word dropping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
